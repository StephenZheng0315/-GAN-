{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageGeneratorDCGAN2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OpECskheVj6",
        "colab_type": "text"
      },
      "source": [
        "# Remote Sensing Image Generation using GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8cyZxpGeftj",
        "colab_type": "text"
      },
      "source": [
        "##Dataset used: RSI-CB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3GVey70eLcv",
        "colab_type": "text"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhFGtaNIyJl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pyunpack\n",
        "#!pip install patool\n",
        "url = 'https://public.sn.files.1drv.com/y4mYvqnmIYFMlKI9sD4Op_TbZRMbTRpQU0hdcorNRynCi-3MoUymHLC25SL2vrxSslUnDcclYq2Svt24w5xZFmwDHdgBrQ5YRG5ZlStBe3b3FA7aRMa95sOSzHeR53Quc_Y6cbVSM_7lYJT8rbFkBJdMDgLyI5VonfZXRaoSPwWf8p9XAlET8vci8fN4gT8VxJOI8FyoMtE0DgymXZ175M43w/RSI-CB128.rar?access_token=EwD4Aq1DBAAUcSSzoTJJsy%2bXrnQXgAKO5cj4yc8AAdDqDp%2bttiSWdJAQiYLCrv4V2%2fP0chEEmx5pOplb7kr92xZAuvmafi3tOFbksIbNjVo16BRtR3Xr2lkP%2bwdVYZLaaAJpeBRhRb8EjH2lGEAOjnpxOBms8%2f9YkqSfFJl5lt05zabufrbrsQzwQWFILrooIVEUir3FBsbvMHtzNlnag59yRL5FLG6yz%2f8CEZxCvwTqoc99otP728VHz5XxDhuPKGXwNR8WnB0x4KFayB%2b%2fI28d9%2fyvwd4E9WPEu%2bNCKOQOiLg%2bEkJjmrxkEkqDL3M%2bKemRD1uPbtriA5wjqUeavNMPbcqAWMakjGeNANeeoA8RDDKll9wxlKAH9Cy9yzQDZgAACBnksjgL%2bWVEyAGHVEqzboeH%2b1q6xyP4vcJ%2fa%2ba0Q1vvGTllAOGG72x0uDuzcM1qChjyRQ%2f0wIofyGG%2f8ttn7%2fmUzYWFU7l%2fQH5LdLIpWnNISpDldndok2xfkiLzAICEePjZ0BLMUFAUFTkCEhfwhZWq%2bw7PsFuUpE02dKOeT4rPt8gXC6pKIT96nm6jhGpNifMldIoq9tfBSShmyaUk2BpwAAAJmbQ%2bISZ2nwayFxuTvpbZHBfCC7rgQSzguWUPtDJmJYUtfwDBb92geXvtrWL0SoXQmnX5q1x1QeBILNmJKJ%2fTkKNDtngiJU0%2bYOFl88CaSXunig0Orsp%2fps%2bbMdzlswkF38h6r7pM2hLmu1lWwimEPHRBr35fLKntaSbqSbpCjgMG0%2fDM8gzgKqgZmQmazaLXm%2bWppFWAZ0oLQwnEMYvsnykYRrwNoX1FchqMLJ4Vlhi%2bohgH2gkjW7IXY3Vns6G3iAHESXRwdLjSimD6n6ptrD07HSHXZZ9B3NPPqAwhR1OenWbe3VN4CMsO6%2fdkNMKyILBzMHA8vETiX%2b%2bL47rQwjZ3rAcISyxgmSSdZ9T7i2ufYPZyL6FkLDFv%2fCLQIUEVMH9HBecmyp%2bruRTBNwgHAg%3d%3d'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3yBhS0djQS0",
        "colab_type": "text"
      },
      "source": [
        "##Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "267d5504009eca2b809a2691131366baebe98436",
        "id": "lfN7mdFp7-Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import datetime\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from urllib.request import urlretrieve\n",
        "from pyunpack import Archive\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ZdMRVres2U",
        "colab_type": "text"
      },
      "source": [
        "##Create Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA4A_uuo6-z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/'\n",
        "\n",
        "if not os.path.exists(path + 'rsensing'):\n",
        "    os.makedirs(path + 'rsensing')\n",
        "    \n",
        "if not os.path.exists(path + 'rsensing' + '/data'):\n",
        "    os.makedirs(path + 'rsensing' + '/data')\n",
        "    \n",
        "if not os.path.exists(path + 'rsensing' + '/generated'):\n",
        "    os.makedirs(path + 'rsensing' + '/generated')\n",
        "    \n",
        "INPUT_DATA_DIR = path + \"rsensing/data/RSI-CB128/water area/hirst/\" \n",
        "OUTPUT_DIR = path + 'rsensing/generated/'   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4iCbVYKjVI7",
        "colab_type": "text"
      },
      "source": [
        "## Download and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l89a62y3yXUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD DATASET\n",
        "\n",
        "data_dir = str(path) + 'rsensing/data/'\n",
        "\n",
        "if not os.path.exists(data_dir + 'RSI-CB128.rar'):\n",
        "  \n",
        "  class DLProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "  with DLProgress(unit='B', unit_scale=True, miniters=1, desc='RSI-CB Data Set') as pbar:\n",
        "        urlretrieve(str(url), data_dir + 'RSI-CB128.rar', pbar.hook)\n",
        "\n",
        "    \n",
        "# EXTRACT DATASET    \n",
        "if not os.path.exists(str(data_dir) + 'RSI-CB128'):\n",
        "  Archive(str(data_dir) + 'RSI-CB128.rar').extractall(str(data_dir))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H66rF2pCezva",
        "colab_type": "text"
      },
      "source": [
        "### Define Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GGMjH937-Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 128\n",
        "NOISE_SIZE = 100\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 300\n",
        "EPSILON = 0.00005\n",
        "samples_num = 5\n",
        "LR_P = [0.00004, 0.0004]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zglF71jaNQ",
        "colab_type": "text"
      },
      "source": [
        "## Generator\n",
        "\n",
        "*   Input: random vector noise of size  100\n",
        "*   Output: Generated RGB Image of shape 128 X 128 X 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fc376df46433261bfeb643a95793718a9d969ed1",
        "id": "s4Ncni897-Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(z, output_channel_dim, training):\n",
        "    with tf.variable_scope(\"generator\", reuse= not training):\n",
        "      \n",
        "        WEIGHT_INIT_STDDEV = 0.02\n",
        "        k_init = tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV)\n",
        "        kernel = [5,5]\n",
        "        strides = [2,2]\n",
        "        \n",
        "        \n",
        "        # 8x8x1024        \n",
        "        fully_connected = tf.layers.dense(z, 8*8*8*IMAGE_SIZE)\n",
        "        fully_connected = tf.reshape(fully_connected, (-1, 8, 8, 8*IMAGE_SIZE))\n",
        "        fully_connected = tf.nn.leaky_relu(fully_connected)\n",
        "\n",
        "        \n",
        "        # 8x8x1024 -> 16x16x512\n",
        "        trans_conv1 = tf.layers.conv2d_transpose(fully_connected, 3*IMAGE_SIZE, kernel, strides, \"SAME\",\n",
        "                                                                              kernel_initializer=k_init) \n",
        "        batch_trans_conv1 = tf.layers.batch_normalization(trans_conv1, training=training, epsilon=EPSILON)\n",
        "        \n",
        "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1)\n",
        "        \n",
        "        \n",
        "        # 16x16x512 -> 32x32x256\n",
        "        trans_conv2 = tf.layers.conv2d_transpose(trans_conv1_out,2*IMAGE_SIZE,kernel, strides,\"SAME\",\n",
        "                                                                           kernel_initializer=k_init)             \n",
        "        batch_trans_conv2 = tf.layers.batch_normalization(trans_conv2, training=training, epsilon=EPSILON)        \n",
        "        \n",
        "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # 32x32x256 -> 64x64x128\n",
        "        trans_conv3 = tf.layers.conv2d_transpose(trans_conv2_out,IMAGE_SIZE,kernel, strides,\"SAME\",\n",
        "                                                                         kernel_initializer=k_init)        \n",
        "        batch_trans_conv3 = tf.layers.batch_normalization(trans_conv3, training=training, epsilon=EPSILON)\n",
        "        \n",
        "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3)\n",
        "        \n",
        "        \n",
        "        # 64x64x128 -> 128x128x64\n",
        "        trans_conv4 = tf.layers.conv2d_transpose(trans_conv3_out,int(IMAGE_SIZE/2),kernel, strides,\"SAME\",\n",
        "                                                                                kernel_initializer=k_init)       \n",
        "        batch_trans_conv4 = tf.layers.batch_normalization(trans_conv4, training=training, epsilon=EPSILON)\n",
        "        \n",
        "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4)\n",
        "        \n",
        "        \n",
        "        # 128x128x64 -> 128x128x3\n",
        "        logits = tf.layers.conv2d_transpose(trans_conv4_out,3,kernel,[1,1],\"SAME\",\n",
        "                                                        kernel_initializer=k_init)\n",
        "        \n",
        "        out = tf.tanh(logits, name=\"out\")\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fsq-EKGuVsZ",
        "colab_type": "text"
      },
      "source": [
        "##Discriminator\n",
        "\n",
        "*   Input: 128 X 128 X 3 RGB image\n",
        "*   Output: It's probability of being real\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ba53a4bb09dbcd57d3e3392f74ccd054ecf23ecb",
        "id": "3Vb2TtTT7-S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator(x, reuse):\n",
        "    with tf.variable_scope(\"discriminator\", reuse=reuse): \n",
        "        \n",
        "        WEIGHT_INIT_STDDEV = 0.02\n",
        "        k_init = tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV)\n",
        "        kernel = [5,5]\n",
        "        stride = [2,2]\n",
        "        # 128*128*3 -> 64x64x64 \n",
        "        \n",
        "        \n",
        "        conv1 = tf.layers.conv2d(x,int(IMAGE_SIZE/2),kernel, stride,\"SAME\", kernel_initializer=k_init)        \n",
        "        batch_norm1 = tf.layers.batch_normalization(conv1, training=True, epsilon=EPSILON)        \n",
        "        conv1_out = tf.nn.leaky_relu(batch_norm1)\n",
        "        \n",
        "        \n",
        "        # 64x64x64-> 32x32x128 \n",
        "        conv2 = tf.layers.conv2d(conv1_out,IMAGE_SIZE,kernel, stride,\"SAME\", kernel_initializer=k_init)       \n",
        "        batch_norm2 = tf.layers.batch_normalization(conv2, training=True, epsilon=EPSILON)        \n",
        "        conv2_out = tf.nn.leaky_relu(batch_norm2)\n",
        "        \n",
        "        \n",
        "        # 32x32x128 -> 16x16x256  \n",
        "        conv3 = tf.layers.conv2d(conv2_out,2*IMAGE_SIZE,kernel, stride,\"SAME\", kernel_initializer=k_init)        \n",
        "        batch_norm3 = tf.layers.batch_normalization(conv3, training=True, epsilon=EPSILON)        \n",
        "        conv3_out = tf.nn.leaky_relu(batch_norm3)\n",
        "        \n",
        "        \n",
        "        # 16x16x256 -> 16x16x512\n",
        "        conv4 = tf.layers.conv2d(conv3_out,3*IMAGE_SIZE,kernel,[1, 1],\"SAME\", kernel_initializer=k_init)        \n",
        "        batch_norm4 = tf.layers.batch_normalization(conv4, training=True, epsilon=EPSILON)        \n",
        "        conv4_out = tf.nn.leaky_relu(batch_norm4)\n",
        "        \n",
        "        \n",
        "        # 16x16x512 -> 8x8x1024\n",
        "        conv5 = tf.layers.conv2d(conv4_out,8*IMAGE_SIZE,kernel, stride,\"SAME\", kernel_initializer=k_init)        \n",
        "        batch_norm5 = tf.layers.batch_normalization(conv5, training=True, epsilon=EPSILON)        \n",
        "        conv5_out = tf.nn.leaky_relu(batch_norm5)\n",
        "\n",
        "        \n",
        "        flatten = tf.reshape(conv5_out, (-1, 8*8*8*IMAGE_SIZE))\n",
        "        \n",
        "        logits = tf.layers.dense(inputs=flatten, units=1, activation=None)\n",
        "        \n",
        "        out = tf.sigmoid(logits)\n",
        "        \n",
        "        return out, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIVZdG1ie7cM",
        "colab_type": "text"
      },
      "source": [
        "## Calculate loss and optimize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8ef5bbb8e4d157577f1b15600aa64cb40289a754",
        "id": "9SCtDMJW7-S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_loss(input_real, input_z, output_channel_dim):\n",
        "    \n",
        "    BETA1 = 0.5\n",
        "    LR_D, LR_G = LR_P\n",
        "\n",
        "    g_model = generator(input_z, output_channel_dim, True)\n",
        "\n",
        "    noisy_input_real = input_real + tf.random_normal(shape=tf.shape(input_real), mean=0.0,\n",
        "                                                     stddev=random.uniform(0.0, 0.1), dtype=tf.float32)\n",
        "    \n",
        "    d_model_real, d_logits_real = discriminator(noisy_input_real, reuse=False)\n",
        "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
        "    \n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
        "                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                         labels=tf.zeros_like(d_model_fake)))\n",
        "    d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
        "                                                                    labels=tf.ones_like(d_model_fake)))\n",
        "    \n",
        "    t_vars = tf.trainable_variables()\n",
        "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
        "    \n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    gen_updates = [op for op in update_ops if op.name.startswith('generator')]\n",
        "    \n",
        "    with tf.control_dependencies(gen_updates):\n",
        "        d_train_opt = tf.train.AdamOptimizer(learning_rate=LR_D, beta1=BETA1).minimize(d_loss, var_list=d_vars)\n",
        "        g_train_opt = tf.train.AdamOptimizer(learning_rate=LR_G, beta1=BETA1).minimize(g_loss, var_list=g_vars)  \n",
        "    return d_loss, g_loss, d_train_opt, g_train_opt\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUA2QVJXfGGZ",
        "colab_type": "text"
      },
      "source": [
        "## Create Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATfiI867-TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_inputs(real_dim, z_dim):\n",
        "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
        "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
        "    learning_rate_G = tf.placeholder(tf.float32, name=\"lr_g\")\n",
        "    learning_rate_D = tf.placeholder(tf.float32, name=\"lr_d\")\n",
        "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7JIlld5fSQg",
        "colab_type": "text"
      },
      "source": [
        "## Display loss and sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0ed8f1c378f936ac81ae89b35d5b6914cd6efbbb",
        "id": "zB5Fd6pG7-TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_loss(epoch, time, sess, d_losses, g_losses, input_z, data_shape):\n",
        "  \n",
        "    minibatch_size = int(data_shape[0]//BATCH_SIZE)\n",
        "    \n",
        "    print(\"Epoch {}/{}\".format(epoch, EPOCHS))\n",
        "    print(\"Duration: \", round(time, 5))\n",
        "    print(\"D_Loss: \", round(np.mean(d_losses[-minibatch_size:]), 5))\n",
        "    print(\"G_Loss: \", round(np.mean(g_losses[-minibatch_size:]), 5))\n",
        "          \n",
        "    out_channel_dim = data_shape[3]\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
        "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
        "    plt.title(\"Losses\")\n",
        "    plt.legend()\n",
        "    plt.savefig(OUTPUT_DIR + \"losses_\" + str(epoch) + \".png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    example_z = np.random.uniform(-1, 1, size=[samples_num, input_z.get_shape().as_list()[-1]])\n",
        "    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n",
        "    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
        "\n",
        "    show_samples(sample_images, OUTPUT_DIR + \"samples\", epoch)\n",
        "\n",
        "    \n",
        "def show_samples(sample_images, name, epoch):\n",
        "  for i in range(5):\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.show()\n",
        "    img = Image.fromarray(np.uint8((sample_images[i]) * 255))\n",
        "    img.save(str(OUTPUT_DIR) + str(epoch) + '_' + str(i) + '.png')\n",
        "\n",
        "  plt.close()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF5sf58WffI_",
        "colab_type": "text"
      },
      "source": [
        "## Create Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ISxrEAf7-TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(data):\n",
        "    batches = []\n",
        "    for i in range(int(data.shape[0]//BATCH_SIZE)):\n",
        "        batch = data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "        augmented_images = []\n",
        "        for img in batch:\n",
        "            image = Image.fromarray(img)\n",
        "            if random.choice([True, False]):\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            augmented_images.append(np.asarray(image))\n",
        "        batch = np.asarray(augmented_images)\n",
        "        normalized_batch = (batch / 127.5) - 1.0\n",
        "        batches.append(normalized_batch)\n",
        "    return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VJtriHlflHm",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLmTLkEG7-TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(get_batches, data_shape, checkpoint_to_load=None):\n",
        "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], NOISE_SIZE)\n",
        "    d_loss, g_loss, d_opt, g_opt = model_loss(input_images, input_z, data_shape[3])\n",
        "    \n",
        "    LR_D, LR_G = LR_P\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        epoch = 0\n",
        "        iteration = 0\n",
        "        d_losses = []\n",
        "        g_losses = []\n",
        "        \n",
        "        for epoch in range(EPOCHS):        \n",
        "            epoch += 1\n",
        "            t1 = time.time()\n",
        "\n",
        "            for batch_images in get_batches:\n",
        "                iteration += 1\n",
        "                batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_SIZE))\n",
        "                _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: LR_D})\n",
        "                _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: LR_G})\n",
        "\n",
        "                d_losses.append(d_loss.eval({input_z: batch_z, input_images: batch_images}))\n",
        "                g_losses.append(g_loss.eval({input_z: batch_z}))\n",
        "\n",
        "            display_loss(epoch, time.time()-t1, sess, d_losses, g_losses, input_z, data_shape)\n",
        "            \n",
        "            #  S A V I N G  M O D E L        \n",
        "\n",
        "            if epoch % 10 == 0 and epoch != 0:\n",
        "              if not os.path.exists(path + 'rsensing/saved_model'):\n",
        "                  os.makedirs(path + 'rsensing/saved_model')\n",
        "              saver.save(sess, path + 'rsensing/saved_model' + '/model-' + str(epoch) + '.cptk')\n",
        "              print (\"Model Saved:\", str(epoch) + '.cptk')\n",
        "          \n",
        "          \n",
        "input_images = np.asarray([np.asarray(Image.open(file).resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_DATA_DIR + '*')])\n",
        "print (\"Input: \" + str(input_images.shape))\n",
        "\n",
        "np.random.shuffle(input_images)\n",
        "\n",
        "sample_images = random.sample(list(input_images), samples_num)\n",
        "show_samples(sample_images, OUTPUT_DIR + \"inputs\", 0)\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    train(get_batches(input_images), input_images.shape)            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}